{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These training steps are the same for first and second stage training. There are two differences:\n",
    "\n",
    "# 1. In the first stage training human annotated rationales are inlcuded, \n",
    "#   whereas in the second stage training rationales are included suggested by the porposed explainabilitt method.\n",
    "\n",
    "# 2. In the first stage training run for 3 epochs, for second stage training run for 100 epochs (or till you get the best performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Ty8WKqTD7c4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"read file here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wgu0hYCdEBNy",
    "outputId": "f8832e46-59f2-474f-ed86-f17ed5b8fc3e"
   },
   "outputs": [],
   "source": [
    "# prompt: train test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming 'df' is your pandas DataFrame with 'cleaned' and 'is_hateful' columns\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.15, random_state=42)  # Adjust test_size and random_state as needed\n",
    "\n",
    "print(f\"Training data size: {len(train_df)}\")\n",
    "print(f\"Testing data size: {len(test_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8GDWWuA5D6Uw",
    "outputId": "7fb0e5d6-b5b4-44c3-87bd-90d114f4feb2"
   },
   "outputs": [],
   "source": [
    "train_df['text'] = train_df['text'].astype(str).str.strip()  # Ensure all entries are strings and strip whitespace\n",
    "print(f\"Training data size: {len(train_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y8OMcAvNTzpm",
    "outputId": "15f2c9de-93d0-4fa1-f96e-7d742d35d7e5"
   },
   "outputs": [],
   "source": [
    "test_df['text'] = test_df['text'].astype(str).str.strip()  # Ensure all entries are strings and strip whitespace\n",
    "print(f\"Training data size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nKCqjGdvYXju"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class CustomTextDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get text data, ensure it's a string\n",
    "        text = self.data.iloc[idx][\"clean_text\"]\n",
    "        if not isinstance(text, str):\n",
    "            text = \"\"\n",
    "            \n",
    "        # Get the label\n",
    "        label = self.data.iloc[idx][\"label\"]\n",
    "\n",
    "        # Safely evaluate the 'rational_3' column to get the attention vector\n",
    "        try:\n",
    "            attention_vector = eval(self.data.iloc[idx][\"pred_rationales\"])\n",
    "            if not isinstance(attention_vector, list):\n",
    "                attention_vector = []\n",
    "        except (SyntaxError, NameError):\n",
    "            attention_vector = []\n",
    "\n",
    "        # Tokenize the text\n",
    "        inputs = self.tokenizer(text, padding='max_length', truncation=True, max_length=self.max_len, return_tensors=\"pt\")\n",
    "\n",
    "        # Convert attention_vector to a tensor and pad if necessary\n",
    "        attention_vector = torch.tensor(attention_vector, dtype=torch.float)\n",
    "\n",
    "        \n",
    "#          # Safely evaluate the 'rational_3' column to get the attention vector\n",
    "#         try:\n",
    "#             attention_vector = eval(self.data.iloc[idx][\"rational_2\"])\n",
    "#             if not isinstance(attention_vector, list):\n",
    "#                 attention_vector = []\n",
    "#         except (SyntaxError, NameError):\n",
    "#             attention_vector = []\n",
    "        \n",
    " # Tokenize the text\n",
    "        inputs = self.tokenizer(text, padding='max_length', truncation=True, max_length=self.max_len, return_tensors=\"pt\")\n",
    "        tokens = self.tokenizer.tokenize(text)\n",
    "\n",
    "        # Adjust ground truth attention to match subword tokens\n",
    "        adjusted_ground_truth_attention = self.adjust_ground_truth_attention(text, tokens, attention_vector)\n",
    "\n",
    "        # Convert to torch tensor and pad to match max_len\n",
    "        attention_vector = torch.tensor(adjusted_ground_truth_attention, dtype=torch.float)\n",
    "\n",
    "        padding_length = self.max_len - attention_vector.size(0)\n",
    "\n",
    "        if padding_length > 0:\n",
    "            # Pad the attention vector with zeros to match max_len\n",
    "            attention_vector = torch.cat([attention_vector, torch.zeros(padding_length)], dim=0)\n",
    "        else:\n",
    "            # Truncate the attention vector if it's longer than max_len\n",
    "            attention_vector = attention_vector[:self.max_len]\n",
    "\n",
    "        # Tokenized inputs\n",
    "        input_ids = inputs['input_ids'].squeeze(0)  # Remove batch dimension\n",
    "        attention_mask = inputs['attention_mask'].squeeze(0)\n",
    "        token_type_ids = inputs['token_type_ids'].squeeze(0)\n",
    "\n",
    "        # Convert label to tensor\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'token_type_ids': token_type_ids,\n",
    "            'label': label,\n",
    "            'attention_vector': attention_vector  # No unsqueeze(0) here\n",
    "        }\n",
    "    \n",
    "    \n",
    "    def adjust_ground_truth_attention(self, sentence, tokens, ground_truth_attention):\n",
    "        \"\"\"\n",
    "        Adjusts ground truth attention to match the subword tokens generated by the BERT tokenizer.\n",
    "        If a word is split into subwords, the attention for the original word is repeated for each subword.\n",
    "        \"\"\"\n",
    "        adjusted_attention = []\n",
    "        word_idx = 0  # Index for words in sentence.split()\n",
    "\n",
    "        for token in tokens:\n",
    "            # If token starts with '##', it's a subword, so repeat the last attention value\n",
    "            if token.startswith(\"##\"):\n",
    "                adjusted_attention.append(adjusted_attention[-1])\n",
    "            else:\n",
    "                # For new words, append the original ground truth attention value\n",
    "                if word_idx < len(ground_truth_attention):\n",
    "                    adjusted_attention.append(ground_truth_attention[word_idx])\n",
    "                    word_idx += 1\n",
    "                else:\n",
    "                    # Handle cases where the number of tokens exceeds the attention values\n",
    "                    adjusted_attention.append(0)\n",
    "\n",
    "        return adjusted_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "afj5yt4yYviP"
   },
   "outputs": [],
   "source": [
    "class BertWithAttentionSupervision(nn.Module):\n",
    "    def __init__(self, num_labels=2):\n",
    "        super(BertWithAttentionSupervision, self).__init__()\n",
    "        self.bert_classifier = BertForSequenceClassification.from_pretrained(\"google/muril-base-cased\", num_labels=num_labels)\n",
    "        self.attention_loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, labels, ground_truth_attention=None):\n",
    "        outputs = self.bert_classifier(input_ids=input_ids,\n",
    "                                       attention_mask=attention_mask,\n",
    "                                       token_type_ids=token_type_ids,\n",
    "                                       labels=labels,\n",
    "                                       output_attentions=True,\n",
    "                                       return_dict=True)\n",
    "\n",
    "        classification_loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Extract attention scores from the final layer\n",
    "        attention_scores = outputs.attentions[-1][:, :, 0, :]  # CLS token attention across all heads\n",
    "        avg_attention_scores = attention_scores.mean(dim=1)  # Average attention scores across heads\n",
    "\n",
    "        # Calculate attention loss only if ground_truth_attention is provided\n",
    "        attention_loss = 0\n",
    "        if ground_truth_attention is not None:\n",
    "            if ground_truth_attention.size(0) != avg_attention_scores.size(0):\n",
    "                raise ValueError(f\"Expected ground_truth_attention to be of size {avg_attention_scores.size(0)}, but got {ground_truth_attention.size(0)}\")\n",
    "            attention_loss = self.attention_loss_fn(avg_attention_scores, ground_truth_attention)\n",
    "\n",
    "        return logits, classification_loss, attention_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R3sQ8DKnY0q4",
    "outputId": "4623fe31-97f9-4dac-ffb1-1c3ca6a8ae86"
   },
   "outputs": [],
   "source": [
    "# Function to train the model\n",
    "def train_model(model, train_dataloader, eval_dataloader, optimizer, device, alph=0.7, bet=0.3, epochs=30):\n",
    "    model.train()\n",
    "    \n",
    "    acc1 = 0\n",
    "    acc = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Move data to device (GPU or CPU)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch['token_type_ids'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            ground_truth_attention = batch['attention_vector'].to(device)\n",
    "\n",
    "            try:\n",
    "                # Forward pass\n",
    "                logits, classification_loss, attention_loss = model(input_ids=input_ids,\n",
    "                                                                attention_mask=attention_mask,\n",
    "                                                                token_type_ids=token_type_ids,\n",
    "                                                                labels=labels,\n",
    "                                                                ground_truth_attention=ground_truth_attention)\n",
    "\n",
    "                # Total loss with weights\n",
    "                total_batch_loss = alph * attention_loss + bet * classification_loss\n",
    "\n",
    "                # Backpropagation\n",
    "                total_batch_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Accumulate total loss\n",
    "                total_loss += total_batch_loss.item()\n",
    "\n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error in batch: {batch}\")\n",
    "                raise e\n",
    "\n",
    "        avg_loss = total_loss / len(train_dataloader)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Total Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # Evaluate the model after each epoch\n",
    "        acc1 = evaluate_model(model, eval_dataloader, device)\n",
    "        if acc1 > acc:\n",
    "                acc = acc1\n",
    "                print(acc1)\n",
    "            \n",
    "            # Save the trained model\n",
    "                torch.save(model.state_dict(), \"model path\")\n",
    "                print(\"Model updated\")\n",
    "            \n",
    "            \n",
    "# Evaluate model\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch['token_type_ids'].to(device)\n",
    "\n",
    "            logits, _, _ = model(input_ids=input_ids,\n",
    "                                  attention_mask=attention_mask,\n",
    "                                  token_type_ids=token_type_ids,\n",
    "                                  labels=None,\n",
    "                                  ground_truth_attention=None)  # Set to None for evaluation\n",
    "            \n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "            all_labels.extend(batch['label'].cpu().numpy())\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Initialize tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"google/muril-base-cased\")\n",
    "    max_len = 128  # Adjust based on your dataset\n",
    "\n",
    "\n",
    "    # Create dataset and dataloader\n",
    "    dataset = CustomTextDataset(train_df, tokenizer, max_len=max_len)\n",
    "    train_dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "    \n",
    "    eval_dataset = CustomTextDataset(test_df, tokenizer, max_len=max_len)\n",
    "    eval_dataloader = DataLoader(eval_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Initialize model and optimizer\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = BertWithAttentionSupervision(num_labels=2).to(device)\n",
    "\n",
    "    # Resize embeddings after adding new tokens\n",
    "    model.bert_classifier.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "    # Train the model\n",
    "    train_model(model, train_dataloader, eval_dataloader, optimizer, device, alph=0.7, bet=0.3, epochs=100)\n",
    "\n",
    "\n",
    "def evaluate_loaded_model(device):\n",
    "    # Load the tokenizer first\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"path\")\n",
    "    \n",
    "    # Load the saved model for evaluation\n",
    "    loaded_model = BertWithAttentionSupervision(num_labels=2).to(device)\n",
    "    \n",
    "#     # Ensure you resize the embeddings after loading the tokenizer\n",
    "#     loaded_model.bert_classifier.resize_token_embeddings(len(tokenizer))\n",
    "    \n",
    "    loaded_model.load_state_dict(torch.load(\"path\"))\n",
    "    print(\"Model loaded for evaluation.\")\n",
    "\n",
    "    # Create a separate evaluation dataset and dataloader\n",
    "    eval_dataset = CustomTextDataset(test_df, tokenizer, max_len=128)\n",
    "    eval_dataloader = DataLoader(eval_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Evaluate the loaded model\n",
    "    evaluate_model(loaded_model, eval_dataloader, device)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     evaluate_loaded_model(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Evaluate model\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch['token_type_ids'].to(device)\n",
    "\n",
    "            logits, _, _ = model(input_ids=input_ids,\n",
    "                                  attention_mask=attention_mask,\n",
    "                                  token_type_ids=token_type_ids,\n",
    "                                  labels=None,\n",
    "                                  ground_truth_attention=None)  # Set to None for evaluation\n",
    "\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "            all_labels.extend(batch['label'].cpu().numpy())\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    precision = precision_score(all_labels, all_predictions, average='binary')\n",
    "    recall = recall_score(all_labels, all_predictions, average='binary')\n",
    "    f1 = f1_score(all_labels, all_predictions, average='binary')\n",
    "\n",
    "    macro_precision = precision_score(all_labels, all_predictions, average='macro')\n",
    "    macro_recall = recall_score(all_labels, all_predictions, average='macro')\n",
    "    macro_f1 = f1_score(all_labels, all_predictions, average='macro')\n",
    "\n",
    "    print(\"Evaluation Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Macro Precision: {macro_precision:.4f}\")\n",
    "    print(f\"Macro Recall: {macro_recall:.4f}\")\n",
    "    print(f\"Macro F1 Score: {macro_f1:.4f}\")\n",
    "\n",
    "\n",
    "def evaluate_loaded_model(device):\n",
    "    # Load the tokenizer first\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"google/muril-base-cased\")\n",
    "    \n",
    "    # Load the saved model for evaluation\n",
    "    loaded_model = BertWithAttentionSupervision(num_labels=2).to(device)\n",
    "    \n",
    "    # Ensure you resize the embeddings after loading the tokenizer\n",
    "    loaded_model.bert_classifier.resize_token_embeddings(len(tokenizer))\n",
    "    \n",
    "    loaded_model.load_state_dict(torch.load(\"path\"))\n",
    "    print(\"Model loaded for evaluation.\")\n",
    "\n",
    "    # Create a separate evaluation dataset and dataloader\n",
    "    eval_dataset = CustomTextDataset(test_df, tokenizer, max_len=128)\n",
    "    eval_dataloader = DataLoader(eval_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Evaluate the loaded model\n",
    "    evaluate_model(loaded_model, eval_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture cap\n",
    "evaluate_loaded_model(device)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01c05184a14f4392a58c9e92d70d315e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0dfde3e733e947088b4fd766f2094c4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b3b8fd19f734b6f9983b57f69569728": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2831effda3df43e2b2bbffa6a617322e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "331320e713044b8d9e647d8312482848": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_65ffa26830534ee6b818e544a2872a25",
      "placeholder": "​",
      "style": "IPY_MODEL_f87ebf90346f46318580c7cfbe8dc140",
      "value": " 466k/466k [00:00&lt;00:00, 2.44MB/s]"
     }
    },
    "3633f65a53d54458838942bf5ef82bf3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0dfde3e733e947088b4fd766f2094c4e",
      "placeholder": "​",
      "style": "IPY_MODEL_a80a0c9cfc2a47bc97d587d4bec33f82",
      "value": " 48.0/48.0 [00:00&lt;00:00, 3.35kB/s]"
     }
    },
    "37765ac4e0574af6ab10b628c08f4b07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f74f3df8c5f34b30abbdeedc85328e83",
      "placeholder": "​",
      "style": "IPY_MODEL_2831effda3df43e2b2bbffa6a617322e",
      "value": "tokenizer.json: 100%"
     }
    },
    "3b53f458595047a8af63a96f27575145": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ddd5a72809c4a34b73272ada22d94c4",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_78da83e7ccac44acb5adf323a9257f3a",
      "value": 231508
     }
    },
    "45baaba63f804972a8ec674339e3e403": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4872d422e6e14489a59a6de4704e6a77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4fea4282464b49ffb160dc6ca2e1e926": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e7945fe70bf84b62a1c13fdb2de0b0f4",
       "IPY_MODEL_7515a849a8a740af8931707ac453c2bb",
       "IPY_MODEL_3633f65a53d54458838942bf5ef82bf3"
      ],
      "layout": "IPY_MODEL_f0f2b465328d4dada3e6f534aac8fb2e"
     }
    },
    "5548b83ad02c4baaa91c8e7d448afcf3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "65ffa26830534ee6b818e544a2872a25": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ddd5a72809c4a34b73272ada22d94c4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7515a849a8a740af8931707ac453c2bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7cbc89cb81734c3bbca37a233fca95e4",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5548b83ad02c4baaa91c8e7d448afcf3",
      "value": 48
     }
    },
    "78da83e7ccac44acb5adf323a9257f3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7cbc89cb81734c3bbca37a233fca95e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8641202df0e440b3a7d971c33916c171": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "981d58d0a3c1482b8d466e3b7052b6c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c80c33aa9664cddab3aa48f2b3405b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b55801d33a134d52be5520d143df91d4",
      "placeholder": "​",
      "style": "IPY_MODEL_fa0b2d93961c478aa3f9a72c547a6bae",
      "value": "vocab.txt: 100%"
     }
    },
    "a80a0c9cfc2a47bc97d587d4bec33f82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b3c1855c36a143839fe85dd1a8c2fbc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_981d58d0a3c1482b8d466e3b7052b6c0",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_45baaba63f804972a8ec674339e3e403",
      "value": 466062
     }
    },
    "b55801d33a134d52be5520d143df91d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6e5c1d023d54ed2b70ab75b0dbcd352": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9f3ba55354646dba335685050af7984": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9c80c33aa9664cddab3aa48f2b3405b9",
       "IPY_MODEL_3b53f458595047a8af63a96f27575145",
       "IPY_MODEL_ee9ade3cef7b46108a7052409faaf4b4"
      ],
      "layout": "IPY_MODEL_c6e5c1d023d54ed2b70ab75b0dbcd352"
     }
    },
    "e75588faa02b4c058909f7a0bd5195d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_37765ac4e0574af6ab10b628c08f4b07",
       "IPY_MODEL_b3c1855c36a143839fe85dd1a8c2fbc1",
       "IPY_MODEL_331320e713044b8d9e647d8312482848"
      ],
      "layout": "IPY_MODEL_fe22e46f87a34b46b77445b7803e5f1b"
     }
    },
    "e7945fe70bf84b62a1c13fdb2de0b0f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b3b8fd19f734b6f9983b57f69569728",
      "placeholder": "​",
      "style": "IPY_MODEL_01c05184a14f4392a58c9e92d70d315e",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "ee9ade3cef7b46108a7052409faaf4b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8641202df0e440b3a7d971c33916c171",
      "placeholder": "​",
      "style": "IPY_MODEL_4872d422e6e14489a59a6de4704e6a77",
      "value": " 232k/232k [00:00&lt;00:00, 1.76MB/s]"
     }
    },
    "f0f2b465328d4dada3e6f534aac8fb2e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f74f3df8c5f34b30abbdeedc85328e83": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f87ebf90346f46318580c7cfbe8dc140": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fa0b2d93961c478aa3f9a72c547a6bae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fe22e46f87a34b46b77445b7803e5f1b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
